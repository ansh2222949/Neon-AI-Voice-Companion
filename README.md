<div align="center">

# ğŸš€ Neon â€“ AI Voice Companion  
### Local-First â€¢ Voice-Driven â€¢ Experimental AI System

<p>
  <img src="https://img.shields.io/badge/Python-3.10+-blue?style=for-the-badge&logo=python&logoColor=white"/>
  <img src="https://img.shields.io/badge/LLM-Ollama-orange?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Model-Noromaid%20(MistralRP)-purple?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Voice-GPT--SoVITS-ff69b4?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Architecture-Offline%20First-green?style=for-the-badge"/>
</p>

<b>Mode-Driven Intelligence â€¢ Privacy-Focused â€¢ System > Model</b>

</div>

---

## ğŸ§  What Is Neon?

**Neon** is a **local-first AI voice companion** designed to run primarily on your own machine using a **fully offline LLM + voice pipeline**, with optional and tightly-controlled online access.

What started as an experiment evolved into a **full AI system architecture**, not just a chatbot interface.

âš ï¸ **Neon is not a chatbot wrapper.**  
It is a **system-level AI**, where the model is only one component.

---

## ğŸ§¬ Core AI Stack

- ğŸ§  **LLM Engine**  
  - Ollama (local runtime)  
  - **Noromaid (MistralRP-based)** model from Hugging Face  
  - Instruction-tuned for roleplay, personality control & system prompts  

- ğŸ¤ **Speech-to-Text (STT)**  
  - Faster-Whisper (offline, VAD-based)

- ğŸ”Š **Text-to-Speech (TTS)**  
  - GPT-SoVITS (high-quality voice cloning)

---

## âœ¨ Core Philosophy

- ğŸ§  **Local LLM First** â€” No mandatory cloud APIs  
- ğŸ”’ **Privacy-Focused** â€” Data never leaves the machine  
- ğŸ­ **Mode-Driven Intelligence** â€” Behavior adapts to context & emotion  
- ğŸ§ª **Experimental by Design** â€” Built for AI system research  
- ğŸ§© **System > Model** â€” The LLM never makes final decisions  

---

## ğŸ™ï¸ Core Capabilities

- ğŸ¤ **Voice Input** â€” Offline Whisper STT with VAD  
- ğŸ”Š **Voice Output** â€” GPT-SoVITS (custom voice profiles)  
- ğŸ§  **Local LLM Reasoning** â€” Noromaid via Ollama  
- ğŸ˜ **Emotion Engine** â€” Internal mood affects tone & response style  
- ğŸ§  **Persistent Memory** â€” Context survives restarts  
- âš¡ **Dual Input Mode** â€” Text â†” Voice seamlessly  

---

## ğŸ§± System Architecture

**Key Rule:**  
The LLM never speaks directly to the user.

Every response passes through **emotion analysis, memory context, rule filters, and post-processing**.

```mermaid
graph TD;
    User((User)) -- Voice/Text --> Input_Handler;
    Input_Handler -- Audio --> Whisper_STT;
    Whisper_STT -- Text --> Neon_Brain;

    subgraph BRAIN_CORE
        Neon_Brain --> Emotion_Engine;
        Emotion_Engine --> Context_Memory;
        Context_Memory --> Local_LLM;
    end

    Local_LLM -- Raw_Response --> Post_Process;
    Post_Process -- Safe_Text --> GPT_SoVITS_TTS;
    GPT_SoVITS_TTS -- Audio --> Speakers;
```
```ğŸ“‚ Project Structure
Neon/
â”‚
â”œâ”€â”€ main.py                     # Application entry point (Text + Voice)
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ brain/
â”‚   â”œâ”€â”€ llm.py                  # Ollama + Noromaid interface
â”‚   â””â”€â”€ prompt.py               # Dynamic system prompts
â”‚
â”œâ”€â”€ core/
â”‚   â””â”€â”€ emotion.py              # Emotion state machine
â”‚
â”œâ”€â”€ memory/
â”‚   â””â”€â”€ memory.py               # Persistent JSON memory
â”‚
â”œâ”€â”€ style/
â”‚   â””â”€â”€ postprocess.py          # Response shaping & safety
â”‚
â”œâ”€â”€ voice/
â”‚   â”œâ”€â”€ hear.py                 # Whisper STT (VAD)
â”‚   â”œâ”€â”€ speak.py                # GPT-SoVITS TTS
â”‚   â”œâ”€â”€ set_model.py            # Voice model loader
â”‚   â””â”€â”€ set_reference.py        # Voice reference config
â”‚
â””â”€â”€ .gitignore
```
â–¶ï¸ How To Run
```1ï¸âƒ£ Requirements
Python 3.10+

Ollama (running locally)

GPT-SoVITS API (default port: 9880)
```
```2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
```
```3ï¸âƒ£ Start Neon
python main.py
```
Neon launches in interactive mode
â†’ Type text or press Enter to speak.

ğŸ§ª Project Status
âœ… Core system functional
âœ… Whisper + SoVITS fully working
âœ… Emotion & memory pipeline stable

âš ï¸ Experimental
âš ï¸ Architecture locked for iteration & research

âš ï¸ Disclaimer
This project is built for learning, experimentation, and AI system design research.
It is not a commercial product.

<div align="center">
ğŸ§  Author
<b>Ansh</b>
<i>B.Tech CSE</i>

<b>Focus Areas</b>
AI Systems (not just models) â€¢ Offline-First AI â€¢ Controlled & Safe AI Design

<i>â€œNeon is not about how smart the model is.
Itâ€™s about how controlled, safe, and purposeful AI should be.â€</i>

</div> 
