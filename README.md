<div align="center">

# ğŸš€ Neon â€“ AI Voice Companion  
### Local-First â€¢ Voice-Driven â€¢ Experimental AI System

<p>
  <img src="https://img.shields.io/badge/Python-3.10+-blue?style=for-the-badge&logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/LLM-Ollama-orange?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Voice-GPT--SoVITS-ff69b4?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Architecture-Offline%20First-green?style=for-the-badge" />
</p>

<b>Mode-Driven Intelligence â€¢ Privacy Focused â€¢ System &gt; Model</b>

</div>

---

## ğŸ§  What Is Neon?

**Neon** is a local-first AI voice companion designed to run primarily on your own machine using a **fully local LLM pipeline**, with optional and tightly controlled online access.

What started as an experiment gradually evolved into a **complete AI system architecture** featuring:

- ğŸ­ **Emotion-Aware Responses** â€” internal state affects tone  
- ğŸ§  **Persistent Memory** â€” context awareness across sessions  
- ğŸ—£ï¸ **Real-Time Voice** â€” Whisper (STT) + GPT-SoVITS (TTS)  
- âš¡ **Dual Input Mode** â€” seamless text & voice switching  

âš ï¸ **This is not a chatbot wrapper.**  
Neon is an **AI system**, not just a model interface.

---

## âœ¨ Core Philosophy

- ğŸ§  **Local LLM First** â€” No mandatory cloud LLM APIs  
- ğŸ”’ **Privacy-Focused** â€” Data stays on the userâ€™s machine  
- ğŸ¯ **Mode-Driven Intelligence** â€” Behavior changes with context  
- ğŸ§ª **Experimental by Design** â€” Built for system-level exploration  
- ğŸ§© **System &gt; Model** â€” The LLM is a tool, not the decision-maker  

---

## ğŸ™ï¸ Core Capabilities

- ğŸ¤ **Voice Input** â€” Faster-Whisper (offline STT with VAD)  
- ğŸ”Š **Voice Output** â€” GPT-SoVITS (high-quality custom TTS)  
- ğŸ§  **Local LLM** â€” Ollama (Mistral / LLaMA based)  
- ğŸ˜ **Emotion Engine** â€” mood derived from conversation context  
- ğŸ”Œ **Offline-First Operation** â€” works without internet  

---

## ğŸ§± System Architecture

**Key Principle:**  
The LLM never directly controls responses.

All outputs pass through emotion analysis, rule constraints, and post-processing filters.

```mermaid
graph TD;
    User((User)) -- Voice/Text --> Input_Handler;
    Input_Handler -- Audio --> Whisper_STT;
    Whisper_STT -- Text --> Neon_Brain;

    subgraph BRAIN_CORE
        Neon_Brain --> Emotion_Engine;
        Emotion_Engine --> Context_Memory;
        Context_Memory --> Local_LLM;
    end

    Local_LLM -- Response --> Post_Process;
    Post_Process -- Text --> GPT_SoVITS_TTS;
    GPT_SoVITS_TTS -- Audio --> Speakers;
```
```ğŸ“‚ Project Structure
Neon/
â”‚
â”œâ”€â”€ main.py                     # Application entry point (Dual Input)
â”œâ”€â”€ requirements.txt            # Dependencies
â”‚
â”œâ”€â”€ brain/                      # LLM interaction + logic
â”‚   â”œâ”€â”€ llm.py                  # Ollama interface
â”‚   â””â”€â”€ prompt.py               # Dynamic system prompts
â”‚
â”œâ”€â”€ core/                       # Emotion & safety
â”‚   â””â”€â”€ emotion.py              # Emotion state machine
â”‚
â”œâ”€â”€ memory/                     # Persistent local memory
â”‚   â””â”€â”€ memory.py               # JSON-based storage
â”‚
â”œâ”€â”€ style/                      # Output post-processing
â”‚   â””â”€â”€ postprocess.py
â”‚
â”œâ”€â”€ voice/                      # Audio I/O system
â”‚   â”œâ”€â”€ hear.py                 # Whisper STT (VAD-based)
â”‚   â”œâ”€â”€ speak.py                # GPT-SoVITS TTS + playback
â”‚   â”œâ”€â”€ set_model.py            # Voice model loader
â”‚   â””â”€â”€ set_reference.py        # Reference voice setup
â”‚
â””â”€â”€ .gitignore                  # Runtime & private data ignored
```
â–¶ï¸ How To Run
1ï¸âƒ£ Requirements
Python 3.10+

Ollama installed & running

GPT-SoVITS API running locally (default: port 9880)

```2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
```
```3ï¸âƒ£ Start Neon
python main.py
```
Neon starts in interactive mode.
You can type text or press Enter to speak.

ğŸ§ª Project Status
âœ… Core system functional

âœ… Voice input (Whisper) & output (SoVITS) working

âœ… Emotion & memory pipeline stable

âš ï¸ Experimental (architecture locked for iteration)

âš ï¸ Disclaimer
This is an experimental project built for learning, research, and AI system design exploration.
It is not a commercial product.

<div align="center">
ğŸ§  Author
<b>Ansh</b>
<i>B.Tech CSE</i>

<b>Focus Areas</b>
AI Systems (not just models) â€¢ Offline-First Architecture â€¢ Controlled & Safe AI Design

<i> "Neon is not about how smart the model is. Itâ€™s about how controlled, safe, and purposeful AI should be." </i> </div> ```
